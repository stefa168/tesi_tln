{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Dataset preparation",
   "id": "a30cb6d1b38176d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T17:26:41.388929Z",
     "start_time": "2024-10-31T17:26:41.379684Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gc import set_debug\n",
    "\n",
    "import pandas as pd\n",
    "import itertools\n",
    "\n",
    "ds = pd.read_json('filtered_data.json')\n",
    "\n",
    "ds['tokens'] = ds['Text'].apply(lambda t: t.split(' '))\n",
    "ds['ne'] = ds['tokens'].apply(lambda l: list(itertools.repeat('O', len(l))))\n",
    "\n",
    "ds.to_json('./output.json', orient=\"records\")"
   ],
   "id": "df5e8d79d7dd82f6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "ca2372833917e4c3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T17:26:41.402895Z",
     "start_time": "2024-10-31T17:26:41.393197Z"
    }
   },
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = pd.read_json(\"ner_data.json\")\n",
    "\n",
    "ne_label_col = dataset['ne']\n",
    "label_list = set(itertools.chain.from_iterable(ne_label_col))\n",
    "\n",
    "label_to_id = {label: i for i, label in enumerate(label_list)}\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "num_labels = len(label_list)\n",
    "\n",
    "# Split the dataset into train and temporary datasets (80% train, 20% temporary)\n",
    "train_dataset, temp_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the temporary dataset into validation and test datasets (50% validation, 50% test)\n",
    "val_dataset, test_dataset = train_test_split(temp_dataset, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the datasets to JSON files\n",
    "train_dataset.to_json('train_data.json', orient=\"records\")\n",
    "val_dataset.to_json('val_data.json', orient=\"records\")\n",
    "test_dataset.to_json('test_data.json', orient=\"records\")"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T17:26:41.635086Z",
     "start_time": "2024-10-31T17:26:41.447728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples['tokens'].tolist(), truncation=True, is_split_into_words=True)\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples['ne']):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        label_ids = []\n",
    "        previous_word_idx = None\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label_to_id[label[word_idx]])\n",
    "            else:\n",
    "                label_ids.append(label_to_id[label[word_idx]] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs['labels'] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "\n",
    "label_all_tokens = True\n",
    "train_dataset = tokenize_and_align_labels(train_dataset)\n",
    "val_dataset = tokenize_and_align_labels(val_dataset)\n",
    "test_dataset = tokenize_and_align_labels(test_dataset)\n"
   ],
   "id": "820a304131be4944",
   "outputs": [],
   "execution_count": 29
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
