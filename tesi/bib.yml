unitotmplt:
  type: Repository
  title: "UniTO typst template"
  url: "https://github.com/eduardz1/UniTO-typst-template"

typst:
  type: Web
  title: "Typst"
  url: "http://typst.app"

eliza:
  type: article
  title: ELIZA—a computer program for the study of natural language communication between man and machine
  author: Weizenbaum, Joseph
  date: 1966-01
  page-range: 36-45
  url: https://doi.org/10.1145/365153.365168
  serial-number:
    doi: 10.1145/365153.365168
    issn: 0001-0782
  parent:
    type: periodical
    title: Commun. ACM
    publisher: Association for Computing Machinery
    location: New York, NY, USA
    issue: 1
    volume: 9

rogers:
  type: article
  title: The Necessary and Sufficient Conditions of Psychotherapeutic Personality Change
  author: ROGERS, CARL
  date: 2007
  page-range: 240-8
  serial-number:
    doi: 10.1037/0033-3204.44.3.240
  parent:
    type: periodical
    title: Psychotherapy (Chicago, Ill.)
    volume: 44

eliza_history:
  type: article
  title: "The computational therapeutic: exploring Weizenbaum's ELIZA as a history of the present"
  author: Bassett, Caroline
  date: 2019-12-01
  page-range: 803-812
  url: https://doi.org/10.1007/s00146-018-0825-9
  serial-number:
    doi: 10.1007/s00146-018-0825-9
    issn: 1435-5655
  abstract: This paper explores the history of ELIZA, a computer programme approximating a Rogerian therapist, developed by Jospeh Weizenbaum at MIT in the 1970s, as an early AI experiment. ELIZA's reception provoked Weizenbaum to re-appraise the relationship between `computer power and human reason' and to attack the `powerful delusional thinking' about computers and their intelligence that he understood to be widespread in the general public and also amongst experts. The root issue for Weizenbaum was whether human thought could be `entirely computable' (reducible to logical formalism). This also provoked him to re-consider the nature of machine intelligence and to question the instantiation of its logics in the social world, which would come to operate, he said, as a `slow acting poison'. Exploring Weizenbaum's 20th Century apostasy, in the light of ELIZA, illustrates ways in which contemporary anxieties and debates over machine smartness connect to earlier formations. In particular, this article argues that it is in its designation as a computational therapist that ELIZA is most significant today. ELIZA points towards a form of human-machine relationship now pervasive, a precursor of the `machinic therapeutic' condition we find ourselves in, and thus speaks very directly to questions concerning modulation, autonomy, and the new behaviorism that are currently arising.
  parent:
    type: periodical
    title: AI {&} SOCIETY
    issue: 4
    volume: 34

jm3:
  type: book
  title: "Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models"
  author:
    - Jurafsky, Daniel
    - Martin, James H.
  date: 2025
  edition: 3rd
  url: https://web.stanford.edu/~jurafsky/slp3/

ABRAHAMS196951:
  type: anthos
  title: Symbol Manipulation Languages
  author: Abrahams, Paul W.
  date: 1969
  editor:
    - Alt, Franz L.
    - Rubinoff, Morris
  page-range: 51-111
  url: https://www.sciencedirect.com/science/article/pii/S0065245808603113
  serial-number:
    doi: https://doi.org/10.1016/S0065-2458(08)60311-3
    issn: 0065-2458
  abstract: "Publisher Summary Symbol manipulation is a branch of computing concerned with the manipulation of unpredictably structured data. Symbol manipulation languages vary in the generality of the lists upon which they operate. The development of such languages from IPL-V through LISP, L6, PL/l, SLIP, SNOBOL, COMIT, and EOL with comments on their relative capabilities, advantages, and disadvantages are presented. These languages may arise either through the embedding of symbol manipulation facilities in a general-purpose language or through the expansion of a symbol manipulation language to include general computation. L6 and EOL are low-level languages. Their simplicity contrasts with the complexity of the higher-level languages. The symbol manipulation must meet two requirements: (1) representation of lists and (2) language features, are also discussed. Pattern-matching is a recurrent theme in symbol manipulation languages. Symbol manipulation is a rapidly expanding branch of computing. It appears likely that symbol manipulation languages will stabilize as their use becomes more widespread, in much the same way as scientific and commercial languages have stabilized."
  parent:
    type: anthology
    publisher: Elsevier
    volume: 9
    parent:
      type: anthology
      title: Advances in Computers

imitation_game:
  type: article
  title: I.—COMPUTING MACHINERY AND INTELLIGENCE
  author: TURING, A. M.
  date: 1950
  page-range: 433–460
  url: https://doi.org/10.1093/mind/LIX.236.433
  serial-number:
    doi: 10.1093/mind/LIX.236.433
    issn: 0026-4423
  parent:
    type: periodical
    title: Mind
    issue: 236
    volume: 59

alice:
  type: chapter
  title: The anatomy of A.L.I.C.E
  author: Wallace, Richard
  date: 2009
  page-range: 181-210
  serial-number:
    doi: 10.1007/978-1-4020-6710-5_13
    isbn: 978-1-4020-9624-2
  parent:
    type: book

aiml:
  type: Web
  title: Artificial Intelligence Markup Language
  organization: AIML Foundation
  url: http://www.aiml.foundation/doc.html

pandas:
  type: repository
  title: pandas - Python Data Analysis Library
  url: https://pandas.pydata.org/

rnn:
  type: chapter
  title: Learning internal representations by error propagation
  author:
    - Rumelhart, D. E.
    - Hinton, G. E.
    - Williams, R. J.
  date: 1986
  page-range: 318-362
  serial-number:
    isbn: 026268053X
  parent:
    type: book
    title: "Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Vol. 1: Foundations"
    publisher: MIT Press
    location: Cambridge, MA, USA

rnn_intro:
  type: misc
  title: "Recurrent Neural Networks (RNNs): A gentle Introduction and Overview"
  author: Schmidt, Robin M.
  date: 2019
  url: https://arxiv.org/abs/1912.05911
  serial-number:
    arxiv: "1912.05911"

colah:
  type: web
  author: Christopher Olah
  title: "Understanding LSTM Networks"
  url: https://colah.github.io/posts/2015-08-Understanding-LSTMs/

rnn_deutch:
  type: article
  title: Untersuchungen zu dynamischen neuronalen Netzen
  author: Hochreiter, Sepp
  date: 1991
  page-range: ""
  parent:
    type: periodical

rnn_difficult:
  type: article
  title: Learning long-term dependencies with gradient descent is difficult
  author:
    - Bengio, Y.
    - Simard, P.
    - Frasconi, P.
  date: 1994-03
  page-range: 157-166
  serial-number:
    doi: 10.1109/72.279181
    issn: 1941-0093
  abstract: Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.<>
  parent:
    type: periodical
    title: IEEE Transactions on Neural Networks
    issue: 2
    volume: 5

lstm:
  type: article
  title: Long Short-Term Memory
  author:
    - Hochreiter, Sepp
    - Schmidhuber, Jürgen
  date: 1997
  page-range: 1735–1780
  url: https://doi.org/10.1162/neco.1997.9.8.1735
  serial-number:
    doi: 10.1162/neco.1997.9.8.1735
    issn: 0899-7667
  abstract: Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.
  parent:
    type: periodical
    title: Neural Computation
    issue: 8
    volume: 9

LINDEMANN2021650:
  type: article
  title: A survey on long short-term memory networks for time series prediction
  author:
    - Lindemann, Benjamin
    - Müller, Timo
    - Vietz, Hannes
    - Jazdi, Nasser
    - Weyrich, Michael
  date: 2021
  page-range: 650–655
  url: https://www.sciencedirect.com/science/article/pii/S2212827121003796
  serial-number:
    doi: https://doi.org/10.1016/j.procir.2021.03.088
    issn: 2212-8271
  abstract: Recurrent neural networks and exceedingly Long short-term memory (LSTM) have been investigated intensively in recent years due to their ability to model and predict nonlinear time-variant system dynamics. The present paper delivers a comprehensive overview of existing LSTM cell derivatives and network architectures for time series prediction. A categorization in LSTM with optimized cell state representations and LSTM with interacting cell states is proposed. The investigated approaches are evaluated against defined requirements being relevant for an accurate time series prediction. These include short-term and long-term memory behavior, the ability for multimodal and multi-step ahead predictions and the according error propagation. Sequence-to-sequence networks with partially conditioning outperform the other approaches, such as bidirectional or associative networks, and are best suited to fulfill the requirements.
  parent:
    type: periodical
    title: Procedia CIRP
    volume: 99

google_voice:
  type: article
  title: "Neon prescription... or rather, New transcription for Google Voice"
  organization: Google Research
  url:
    value: https://blog.google/products/google-voice/neon-prescription-or-rather-new/
    date: 2015-07-23

google_voice_transcription:
  type: article
  title: "The neural networks behind Google Voice transcription"
  organization: Google Research
  url:
    value: https://research.google/blog/the-neural-networks-behind-google-voice-transcription/
    date: 2015-08-11

google_voice_accuracy:
  type: article
  title: "Google voice search: faster and more accurate"
  author:
    - Sak, Haşim
    - Senior, Andrew
    - Rao, Kanishka
    - Beaufays, Françoise
    - Schalkwyk, Johan
  publisher: Google Speech Team
  organization: Google Research
  url:
    value: https://research.google/blog/google-voice-search-faster-and-more-accurate/
    date: 2015-09-24

wu2016googlesneuralmachinetranslation:
  type: misc
  title: "Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation"
  author:
    - Wu, Yonghui
    - Schuster, Mike
    - Chen, Zhifeng
    - Le, Quoc V.
    - Norouzi, Mohammad
    - Macherey, Wolfgang
    - Krikun, Maxim
    - Cao, Yuan
    - Gao, Qin
    - Macherey, Klaus
    - Klingner, Jeff
    - Shah, Apurva
    - Johnson, Melvin
    - Liu, Xiaobing
    - Kaiser, Łukasz
    - Gouws, Stephan
    - Kato, Yoshikiyo
    - Kudo, Taku
    - Kazawa, Hideto
    - Stevens, Keith
    - Kurian, George
    - Patil, Nishant
    - Wang, Wei
    - Young, Cliff
    - Smith, Jason
    - Riesa, Jason
    - Rudnick, Alex
    - Vinyals, Oriol
    - Corrado, Greg
    - Hughes, Macduff
    - Dean, Jeffrey
  date: 2016
  url: https://arxiv.org/abs/1609.08144
  serial-number:
    arxiv: "1609.08144"

google_translate:
  type: article
  title: "A Neural Network for Machine Translation, at Production Scale"
  author:
    - Quoc V. Le
    - Mike Schuster
  publisher: Google Brain Team
  organization: Google Research
  url:
    value: https://research.google/blog/a-neural-network-for-machine-translation-at-production-scale/
    date: 2016-09-27

apple_lstm:
  type: article
  title: "Can Global Semantic Context Improve Neural Language Models?"
  publisher: Frameworks Natural Language Processing Team
  organization: Apple
  url: https://machinelearning.apple.com/research/can-global-semantic-context-improve-neural-language-models

alexa_lstm:
  type: article
  title: Bringing the Magic of Amazon AI and Alexa to Apps on AWS
  url: https://www.allthingsdistributed.com/2016/11/amazon-ai-and-alexa-for-all-aws-apps.html

facebook_lstm:
  type: article
  title: "Transitioning entirely to neural machine translation"
  author: Alexander Sidorov
  organization: Facebook
  url: https://engineering.fb.com/2017/08/03/ml-applications/transitioning-entirely-to-neural-machine-translation/

microsoft_lstm:
  type: article
  title: The Microsoft 2017 Conversational Speech Recognition System
  author:
    - Xiong, W.
    - Wu, L.
    - Alleva, F.
    - Droppo, J.
    - Huang, X.
    - Stolcke, A.
  date: 2018-04
  page-range: 5934–5938
  serial-number:
    doi: 10.1109/ICASSP.2018.8461870
    issn: 2379-190X
  abstract: We describe the latest version of Microsoft's conversational speech recognition system for the Switchboard and CallHome domains. The system adds a CNN-BLSTM acoustic model to the set of model architectures we combined previously, and includes character-based and dialog session aware LSTM language models in rescoring. For system combination we adopt a two-stage approach, whereby acoustic model posteriors are first combined at the senone/frame level, followed by a word-level voting via confusion networks. We also added another language model rescoring step following the confusion network combination. The resulting system yields a 5.1% word error rate on the NIST 2000 Switchboard test set, and 9.8% on the CallHome subset.
  parent:
    type: proceedings
    title: 2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)
    issue: ""
    volume: 0

openai_dota:
  type: article
  title: "The Science Behind OpenAI Five that just Produced One of the Greatest Breakthrough in the History of AI"
  url: https://web.archive.org/web/20191226222000/https://towardsdatascience.com/the-science-behind-openai-five-that-just-produced-one-of-the-greatest-breakthrough-in-the-history-b045bcdc2b69?gi=24b20ef8ca3f

learning_dexterity:
  type: article
  title: "Learning Dexterity"
  abstract: "We’ve trained a human-like robot hand to manipulate physical objects with unprecedented dexterity."
  organization: OpenAI
  url: https://openai.com/index/learning-dexterity/

deepmind_starcraft:
  type: article
  organization: "The AlphaStar Team"
  url: https://deepmind.google/discover/blog/alphastar-grandmaster-level-in-starcraft-ii-using-multi-agent-reinforcement-learning/

schmidhuber2022deeplearningmiraculousyear:
  type: misc
  title: 'Deep Learning: Our Miraculous Year 1990-1991'
  author: Schmidhuber, Juergen
  date: 2022
  url: https://arxiv.org/abs/2005.05744
  serial-number:
    arxiv: '2005.05744'

vaswani2023attentionneed:
  type: misc
  title: Attention Is All You Need
  author:
  - Vaswani, Ashish
  - Shazeer, Noam
  - Parmar, Niki
  - Uszkoreit, Jakob
  - Jones, Llion
  - Gomez, Aidan N.
  - Kaiser, Lukasz
  - Polosukhin, Illia
  date: 2023
  serial-number:
    doi: "10.48550/arXiv.1706.03762"

bert:
  type: misc
  title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
  author:
    - Devlin, Jacob
    - Chang, Ming-Wei
    - Lee, Kenton
    - Toutanova, Kristina
  date: 2019
  serial-number:
    doi: 10.48550/arXiv.1810.04805

bbc_google_fails:
  type: article
  title: "Glue pizza and eat rocks: Google AI search errors go viral"
  author:
    - McMahon, Liv
    - Kleinman, Zoe
  url: https://www.bbc.com/news/articles/cd11gzejgz4o

distilbert:
  type: article
  title: "DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter"
  author:
    - Sanh, Victor
    - Debut, Lysandre
    - Chaumond, Julien
    - Wolf, Thomas
  date: 2020
  url: https://arxiv.org/abs/1910.01108
  serial-number:
    arxiv: "1910.01108"

dont_stop_pretraining:
  type: article
  title: "Don't Stop Pretraining: Adapt Language Models to Domains and Tasks"
  author:
    - Gururangan, Suchin
    - Marasović, Ana
    - Swayamdipta, Swabha
    - Lo, Kyle
    - Beltagy, Iz
    - Downey, Doug
    - Smith, Noah A.
  date: 2020
  url: https://arxiv.org/abs/2004.10964
  serial-number:
    arxiv: "2004.10964"

huggingface_transformers:
  type: article
  title: "HuggingFace's Transformers: State-of-the-art Natural Language Processing"
  author:
    - Wolf, Thomas
    - Debut, Lysandre
    - Sanh, Victor
    - Chaumond, Julien
    - Delangue, Clement
    - Moi, Anthony
    - Cistac, Pierric
    - Rault, Tim
    - Louf, Rémi
    - Funtowicz, Morgan
    - Davison, Joe
    - Shleifer, Sam
    - name: Platen
      given-name: Patrick
      prefix: von
    - Ma, Clara
    - Jernite, Yacine
    - Plu, Julien
    - Xu, Canwen
    - Scao, Teven Le
    - Gugger, Sylvain
    - Drame, Mariama
    - Lhoest, Quentin
    - Rush, Alexander M.
  date: 2020
  serial-number:
    doi: "10.48550/arXiv.1910.03771"  

loebner:
  type: web
  title: The Loebner Prize
  organization: Berkeley University
  url: https://www.ocf.berkeley.edu/~arihuang/academic/research/loebner.html

bert_fine_tuning:
  type: article
  title: "On the Stability of Fine-tuning BERT: Misconceptions, Explanations, and Strong Baselines"
  author:
    - Mosbach, Marius
    - Andriushchenko, Maksym
    - Klakow, Dietrich
  date: 2021
  url: https://arxiv.org/abs/2006.04884
  serial-number:
    doi: "10.48550/arXiv.2006.04884"

ollama:
  title: Ollama - LLM local runner
  type: repository
  organization: Ollama
  url: https://github.com/ollama/ollama

gemma:
  type: article
  title: "Gemma 2: Improving Open Language Models at a Practical Size"
  organization: Google Deep Mind
  author:
    - Team, Gemma
    - Riviere, Morgane
    - Pathak, Shreya
    - Sessa, Pier Giuseppe
    - Hardin, Cassidy
    - Bhupatiraju, Surya
    - Hussenot, Léonard
    - Mesnard, Thomas
    - Shahriari, Bobak
    - Ramé, Alexandre
    - Ferret, Johan
    - Liu, Peter
    - Tafti, Pouya
    - Friesen, Abe
    - Casbon, Michelle
    - Ramos, Sabela
    - Kumar, Ravin
    - Lan, Charline Le
    - Jerome, Sammy
    - Tsitsulin, Anton
    - Vieillard, Nino
    - Stanczyk, Piotr
    - Girgin, Sertan
    - Momchev, Nikola
    - Hoffman, Matt
    - Thakoor, Shantanu
    - Grill, Jean-Bastien
    - Neyshabur, Behnam
    - Bachem, Olivier
    - Walton, Alanna
    - Severyn, Aliaksei
    - Parrish, Alicia
    - Ahmad, Aliya
    - Hutchison, Allen
    - Abdagic, Alvin
    - Carl, Amanda
    - Shen, Amy
    - Brock, Andy
    - Coenen, Andy
    - Laforge, Anthony
    - Paterson, Antonia
    - Bastian, Ben
    - Piot, Bilal
    - Wu, Bo
    - Royal, Brandon
    - Chen, Charlie
    - Kumar, Chintu
    - Perry, Chris
    - Welty, Chris
    - Choquette-Choo, Christopher A.
    - Sinopalnikov, Danila
    - Weinberger, David
    - Vijaykumar, Dimple
    - Rogozińska, Dominika
    - Herbison, Dustin
    - Bandy, Elisa
    - Wang, Emma
    - Noland, Eric
    - Moreira, Erica
    - Senter, Evan
    - Eltyshev, Evgenii
    - Visin, Francesco
    - Rasskin, Gabriel
    - Wei, Gary
    - Cameron, Glenn
    - Martins, Gus
    - Hashemi, Hadi
    - Klimczak-Plucińska, Hanna
    - Batra, Harleen
    - Dhand, Harsh
    - Nardini, Ivan
    - Mein, Jacinda
    - Zhou, Jack
    - Svensson, James
    - Stanway, Jeff
    - Chan, Jetha
    - Zhou, Jin Peng
    - Carrasqueira, Joana
    - Iljazi, Joana
    - Becker, Jocelyn
    - Fernandez, Joe
    - name: Amersfoort
      given-name: Joost
      prefix: van
    - Gordon, Josh
    - Lipschultz, Josh
    - Newlan, Josh
    - Ji, Ju-yeong
    - Mohamed, Kareem
    - Badola, Kartikeya
    - Black, Kat
    - Millican, Katie
    - McDonell, Keelin
    - Nguyen, Kelvin
    - Sodhia, Kiranbir
    - Greene, Kish
    - Sjoesund, Lars Lowe
    - Usui, Lauren
    - Sifre, Laurent
    - Heuermann, Lena
    - Lago, Leticia
    - McNealus, Lilly
    - Soares, Livio Baldini
    - Kilpatrick, Logan
    - Dixon, Lucas
    - Martins, Luciano
    - Reid, Machel
    - Singh, Manvinder
    - Iverson, Mark
    - Görner, Martin
    - Velloso, Mat
    - Wirth, Mateo
    - Davidow, Matt
    - Miller, Matt
    - Rahtz, Matthew
    - Watson, Matthew
    - Risdal, Meg
    - Kazemi, Mehran
    - Moynihan, Michael
    - Zhang, Ming
    - Kahng, Minsuk
    - Park, Minwoo
    - Rahman, Mofi
    - Khatwani, Mohit
    - Dao, Natalie
    - Bardoliwalla, Nenshad
    - Devanathan, Nesh
    - Dumai, Neta
    - Chauhan, Nilay
    - Wahltinez, Oscar
    - Botarda, Pankil
    - Barnes, Parker
    - Barham, Paul
    - Michel, Paul
    - Jin, Pengchong
    - Georgiev, Petko
    - Culliton, Phil
    - Kuppala, Pradeep
    - Comanescu, Ramona
    - Merhej, Ramona
    - Jana, Reena
    - Rokni, Reza Ardeshir
    - Agarwal, Rishabh
    - Mullins, Ryan
    - Saadat, Samaneh
    - Carthy, Sara Mc
    - Cogan, Sarah
    - Perrin, Sarah
    - Arnold, Sébastien M. R.
    - Krause, Sebastian
    - Dai, Shengyang
    - Garg, Shruti
    - Sheth, Shruti
    - Ronstrom, Sue
    - Chan, Susan
    - Jordan, Timothy
    - Yu, Ting
    - Eccles, Tom
    - Hennigan, Tom
    - Kocisky, Tomas
    - Doshi, Tulsee
    - Jain, Vihan
    - Yadav, Vikas
    - Meshram, Vilobh
    - Dharmadhikari, Vishal
    - Barkley, Warren
    - Wei, Wei
    - Ye, Wenming
    - Han, Woohyun
    - Kwon, Woosuk
    - Xu, Xiang
    - Shen, Zhe
    - Gong, Zhitao
    - Wei, Zichuan
    - Cotruta, Victor
    - Kirk, Phoebe
    - Rao, Anand
    - Giang, Minh
    - Peran, Ludovic
    - Warkentin, Tris
    - Collins, Eli
    - Barral, Joelle
    - Ghahramani, Zoubin
    - Hadsell, Raia
    - Sculley, D.
    - Banks, Jeanine
    - Dragan, Anca
    - Petrov, Slav
    - Vinyals, Oriol
    - Dean, Jeff
    - Hassabis, Demis
    - Kavukcuoglu, Koray
    - Farabet, Clement
    - Buchatskaya, Elena
    - Borgeaud, Sebastian
    - Fiedel, Noah
    - Joulin, Armand
    - Kenealy, Kathleen
    - Dadashi, Robert
    - Andreev, Alek
  date: 2024
  serial-number:
    doi: "10.48550/arXiv.2408.00118"

llama3:
  type: article
  title: The Llama 3 Herd of Models
  organization: Meta
  author:
    - Grattafiori, Aaron
    - Dubey, Abhimanyu
    - Jauhri, Abhinav
    - Pandey, Abhinav
    - Kadian, Abhishek
    - Al-Dahle, Ahmad
    - Letman, Aiesha
    - Mathur, Akhil
    - Schelten, Alan
    - Vaughan, Alex
    - Yang, Amy
    - Fan, Angela
    - Goyal, Anirudh
    - Hartshorn, Anthony
    - Yang, Aobo
    - Mitra, Archi
    - Sravankumar, Archie
    - Korenev, Artem
    - Hinsvark, Arthur
    - Rao, Arun
    - Zhang, Aston
    - Rodriguez, Aurelien
    - Gregerson, Austen
    - Spataru, Ava
    - Roziere, Baptiste
    - Biron, Bethany
    - Tang, Binh
    - Chern, Bobbie
    - Caucheteux, Charlotte
    - Nayak, Chaya
    - Bi, Chloe
    - Marra, Chris
    - McConnell, Chris
    - Keller, Christian
    - Touret, Christophe
    - Wu, Chunyang
    - Wong, Corinne
    - Ferrer, Cristian Canton
    - Nikolaidis, Cyrus
    - Allonsius, Damien
    - Song, Daniel
    - Pintz, Danielle
    - Livshits, Danny
    - Wyatt, Danny
    - Esiobu, David
    - Choudhary, Dhruv
    - Mahajan, Dhruv
    - Garcia-Olano, Diego
    - Perino, Diego
    - Hupkes, Dieuwke
    - Lakomkin, Egor
    - AlBadawy, Ehab
    - Lobanova, Elina
    - Dinan, Emily
    - Smith, Eric Michael
    - Radenovic, Filip
    - Guzmán, Francisco
    - Zhang, Frank
    - Synnaeve, Gabriel
    - Lee, Gabrielle
    - Anderson, Georgia Lewis
    - Thattai, Govind
    - Nail, Graeme
    - Mialon, Gregoire
    - Pang, Guan
    - Cucurell, Guillem
    - Nguyen, Hailey
    - Korevaar, Hannah
    - Xu, Hu
    - Touvron, Hugo
    - Zarov, Iliyan
    - Ibarra, Imanol Arrieta
    - Kloumann, Isabel
    - Misra, Ishan
    - Evtimov, Ivan
    - Zhang, Jack
    - Copet, Jade
    - Lee, Jaewon
    - Geffert, Jan
    - Vranes, Jana
    - Park, Jason
    - Mahadeokar, Jay
    - Shah, Jeet
    - name: Linde
      given-name: Jelmer
      prefix: van der
    - Billock, Jennifer
    - Hong, Jenny
    - Lee, Jenya
    - Fu, Jeremy
    - Chi, Jianfeng
    - Huang, Jianyu
    - Liu, Jiawen
    - Wang, Jie
    - Yu, Jiecao
    - Bitton, Joanna
    - Spisak, Joe
    - Park, Jongsoo
    - Rocca, Joseph
    - Johnstun, Joshua
    - Saxe, Joshua
    - Jia, Junteng
    - Alwala, Kalyan Vasuden
    - Prasad, Karthik
    - Upasani, Kartikeya
    - Plawiak, Kate
    - Li, Ke
    - Heafield, Kenneth
    - Stone, Kevin
    - El-Arini, Khalid
    - Iyer, Krithika
    - Malik, Kshitiz
    - Chiu, Kuenley
    - Bhalla, Kunal
    - Lakhotia, Kushal
    - Rantala-Yeary, Lauren
    - name: Maaten
      given-name: Laurens
      prefix: van der
    - Chen, Lawrence
    - Tan, Liang
    - Jenkins, Liz
    - Martin, Louis
    - Madaan, Lovish
    - Malo, Lubo
    - Blecher, Lukas
    - Landzaat, Lukas
    - name: Oliveira
      given-name: Luke
      prefix: de
    - Muzzi, Madeline
    - Pasupuleti, Mahesh
    - Singh, Mannat
    - Paluri, Manohar
    - Kardas, Marcin
    - Tsimpoukelli, Maria
    - Oldham, Mathew
    - Rita, Mathieu
    - Pavlova, Maya
    - Kambadur, Melanie
    - Lewis, Mike
    - Si, Min
    - Singh, Mitesh Kumar
    - Hassan, Mona
    - Goyal, Naman
    - Torabi, Narjes
    - Bashlykov, Nikolay
    - Bogoychev, Nikolay
    - Chatterji, Niladri
    - Zhang, Ning
    - Duchenne, Olivier
    - Çelebi, Onur
    - Alrassy, Patrick
    - Zhang, Pengchuan
    - Li, Pengwei
    - Vasic, Petar
    - Weng, Peter
    - Bhargava, Prajjwal
    - Dubal, Pratik
    - Krishnan, Praveen
    - Koura, Punit Singh
    - Xu, Puxin
    - He, Qing
    - Dong, Qingxiao
    - Srinivasan, Ragavan
    - Ganapathy, Raj
    - Calderer, Ramon
    - Cabral, Ricardo Silveira
    - Stojnic, Robert
    - Raileanu, Roberta
    - Maheswari, Rohan
    - Girdhar, Rohit
    - Patel, Rohit
    - Sauvestre, Romain
    - Polidoro, Ronnie
    - Sumbaly, Roshan
    - Taylor, Ross
    - Silva, Ruan
    - Hou, Rui
    - Wang, Rui
    - Hosseini, Saghar
    - Chennabasappa, Sahana
    - Singh, Sanjay
    - Bell, Sean
    - Kim, Seohyun Sonia
    - Edunov, Sergey
    - Nie, Shaoliang
    - Narang, Sharan
    - Raparthy, Sharath
    - Shen, Sheng
    - Wan, Shengye
    - Bhosale, Shruti
    - Zhang, Shun
    - Vandenhende, Simon
    - Batra, Soumya
    - Whitman, Spencer
    - Sootla, Sten
    - Collot, Stephane
    - Gururangan, Suchin
    - Borodinsky, Sydney
    - Herman, Tamar
    - Fowler, Tara
    - Sheasha, Tarek
    - Georgiou, Thomas
    - Scialom, Thomas
    - Speckbacher, Tobias
    - Mihaylov, Todor
    - Xiao, Tong
    - Karn, Ujjwal
    - Goswami, Vedanuj
    - Gupta, Vibhor
    - Ramanathan, Vignesh
    - Kerkez, Viktor
    - Gonguet, Vincent
    - Do, Virginie
    - Vogeti, Vish
    - Albiero, Vítor
    - Petrovic, Vladan
    - Chu, Weiwei
    - Xiong, Wenhan
    - Fu, Wenyin
    - Meers, Whitney
    - Martinet, Xavier
    - Wang, Xiaodong
    - Wang, Xiaofang
    - Tan, Xiaoqing Ellen
    - Xia, Xide
    - Xie, Xinfeng
    - Jia, Xuchao
    - Wang, Xuewei
    - Goldschlag, Yaelle
    - Gaur, Yashesh
    - Babaei, Yasmine
    - Wen, Yi
    - Song, Yiwen
    - Zhang, Yuchen
    - Li, Yue
    - Mao, Yuning
    - Coudert, Zacharie Delpierre
    - Yan, Zheng
    - Chen, Zhengxing
    - Papakipos, Zoe
    - Singh, Aaditya
    - Srivastava, Aayushi
    - Jain, Abha
    - Kelsey, Adam
    - Shajnfeld, Adam
    - Gangidi, Adithya
    - Victoria, Adolfo
    - Goldstand, Ahuva
    - Menon, Ajay
    - Sharma, Ajay
    - Boesenberg, Alex
    - Baevski, Alexei
    - Feinstein, Allie
    - Kallet, Amanda
    - Sangani, Amit
    - Teo, Amos
    - Yunus, Anam
    - Lupu, Andrei
    - Alvarado, Andres
    - Caples, Andrew
    - Gu, Andrew
    - Ho, Andrew
    - Poulton, Andrew
    - Ryan, Andrew
    - Ramchandani, Ankit
    - Dong, Annie
    - Franco, Annie
    - Goyal, Anuj
    - Saraf, Aparajita
    - Chowdhury, Arkabandhu
    - Gabriel, Ashley
    - Bharambe, Ashwin
    - Eisenman, Assaf
    - Yazdan, Azadeh
    - James, Beau
    - Maurer, Ben
    - Leonhardi, Benjamin
    - Huang, Bernie
    - Loyd, Beth
    - Paola, Beto De
    - Paranjape, Bhargavi
    - Liu, Bing
    - Wu, Bo
    - Ni, Boyu
    - Hancock, Braden
    - Wasti, Bram
    - Spence, Brandon
    - Stojkovic, Brani
    - Gamido, Brian
    - Montalvo, Britt
    - Parker, Carl
    - Burton, Carly
    - Mejia, Catalina
    - Liu, Ce
    - Wang, Changhan
    - Kim, Changkyu
    - Zhou, Chao
    - Hu, Chester
    - Chu, Ching-Hsiang
    - Cai, Chris
    - Tindal, Chris
    - Feichtenhofer, Christoph
    - Gao, Cynthia
    - Civin, Damon
    - Beaty, Dana
    - Kreymer, Daniel
    - Li, Daniel
    - Adkins, David
    - Xu, David
    - Testuggine, Davide
    - David, Delia
    - Parikh, Devi
    - Liskovich, Diana
    - Foss, Didem
    - Wang, Dingkang
    - Le, Duc
    - Holland, Dustin
    - Dowling, Edward
    - Jamil, Eissa
    - Montgomery, Elaine
    - Presani, Eleonora
    - Hahn, Emily
    - Wood, Emily
    - Le, Eric-Tuan
    - Brinkman, Erik
    - Arcaute, Esteban
    - Dunbar, Evan
    - Smothers, Evan
    - Sun, Fei
    - Kreuk, Felix
    - Tian, Feng
    - Kokkinos, Filippos
    - Ozgenel, Firat
    - Caggioni, Francesco
    - Kanayet, Frank
    - Seide, Frank
    - Florez, Gabriela Medina
    - Schwarz, Gabriella
    - Badeer, Gada
    - Swee, Georgia
    - Halpern, Gil
    - Herman, Grant
    - Sizov, Grigory
    - Guangyi
    - Zhang
    - Lakshminarayanan, Guna
    - Inan, Hakan
    - Shojanazeri, Hamid
    - Zou, Han
    - Wang, Hannah
    - Zha, Hanwen
    - Habeeb, Haroun
    - Rudolph, Harrison
    - Suk, Helen
    - Aspegren, Henry
    - Goldman, Hunter
    - Zhan, Hongyuan
    - Damlaj, Ibrahim
    - Molybog, Igor
    - Tufanov, Igor
    - Leontiadis, Ilias
    - Veliche, Irina-Elena
    - Gat, Itai
    - Weissman, Jake
    - Geboski, James
    - Kohli, James
    - Lam, Janice
    - Asher, Japhet
    - Gaya, Jean-Baptiste
    - Marcus, Jeff
    - Tang, Jeff
    - Chan, Jennifer
    - Zhen, Jenny
    - Reizenstein, Jeremy
    - Teboul, Jeremy
    - Zhong, Jessica
    - Jin, Jian
    - Yang, Jingyi
    - Cummings, Joe
    - Carvill, Jon
    - Shepard, Jon
    - McPhie, Jonathan
    - Torres, Jonathan
    - Ginsburg, Josh
    - Wang, Junjie
    - Wu, Kai
    - U, Kam Hou
    - Saxena, Karan
    - Khandelwal, Kartikay
    - Zand, Katayoun
    - Matosich, Kathy
    - Veeraraghavan, Kaushik
    - Michelena, Kelly
    - Li, Keqian
    - Jagadeesh, Kiran
    - Huang, Kun
    - Chawla, Kunal
    - Huang, Kyle
    - Chen, Lailin
    - Garg, Lakshya
    - A, Lavender
    - Silva, Leandro
    - Bell, Lee
    - Zhang, Lei
    - Guo, Liangpeng
    - Yu, Licheng
    - Moshkovich, Liron
    - Wehrstedt, Luca
    - Khabsa, Madian
    - Avalani, Manav
    - Bhatt, Manish
    - Mankus, Martynas
    - Hasson, Matan
    - Lennie, Matthew
    - Reso, Matthias
    - Groshev, Maxim
    - Naumov, Maxim
    - Lathi, Maya
    - Keneally, Meghan
    - Liu, Miao
    - Seltzer, Michael L.
    - Valko, Michal
    - Restrepo, Michelle
    - Patel, Mihir
    - Vyatskov, Mik
    - Samvelyan, Mikayel
    - Clark, Mike
    - Macey, Mike
    - Wang, Mike
    - Hermoso, Miquel Jubert
    - Metanat, Mo
    - Rastegari, Mohammad
    - Bansal, Munish
    - Santhanam, Nandhini
    - Parks, Natascha
    - White, Natasha
    - Bawa, Navyata
    - Singhal, Nayan
    - Egebo, Nick
    - Usunier, Nicolas
    - Mehta, Nikhil
    - Laptev, Nikolay Pavlovich
    - Dong, Ning
    - Cheng, Norman
    - Chernoguz, Oleg
    - Hart, Olivia
    - Salpekar, Omkar
    - Kalinli, Ozlem
    - Kent, Parkin
    - Parekh, Parth
    - Saab, Paul
    - Balaji, Pavan
    - Rittner, Pedro
    - Bontrager, Philip
    - Roux, Pierre
    - Dollar, Piotr
    - Zvyagina, Polina
    - Ratanchandani, Prashant
    - Yuvraj, Pritish
    - Liang, Qian
    - Alao, Rachad
    - Rodriguez, Rachel
    - Ayub, Rafi
    - Murthy, Raghotham
    - Nayani, Raghu
    - Mitra, Rahul
    - Parthasarathy, Rangaprabhu
    - Li, Raymond
    - Hogan, Rebekkah
    - Battey, Robin
    - Wang, Rocky
    - Howes, Russ
    - Rinott, Ruty
    - Mehta, Sachin
    - Siby, Sachin
    - Bondu, Sai Jayesh
    - Datta, Samyak
    - Chugh, Sara
    - Hunt, Sara
    - Dhillon, Sargun
    - Sidorov, Sasha
    - Pan, Satadru
    - Mahajan, Saurabh
    - Verma, Saurabh
    - Yamamoto, Seiji
    - Ramaswamy, Sharadh
    - Lindsay, Shaun
    - Lindsay, Shaun
    - Feng, Sheng
    - Lin, Shenghao
    - Zha, Shengxin Cindy
    - Patil, Shishir
    - Shankar, Shiva
    - Zhang, Shuqiang
    - Zhang, Shuqiang
    - Wang, Sinong
    - Agarwal, Sneha
    - Sajuyigbe, Soji
    - Chintala, Soumith
    - Max, Stephanie
    - Chen, Stephen
    - Kehoe, Steve
    - Satterfield, Steve
    - Govindaprasad, Sudarshan
    - Gupta, Sumit
    - Deng, Summer
    - Cho, Sungmin
    - Virk, Sunny
    - Subramanian, Suraj
    - Choudhury, Sy
    - Goldman, Sydney
    - Remez, Tal
    - Glaser, Tamar
    - Best, Tamara
    - Koehler, Thilo
    - Robinson, Thomas
    - Li, Tianhe
    - Zhang, Tianjun
    - Matthews, Tim
    - Chou, Timothy
    - Shaked, Tzook
    - Vontimitta, Varun
    - Ajayi, Victoria
    - Montanez, Victoria
    - Mohan, Vijai
    - Kumar, Vinay Satish
    - Mangla, Vishal
    - Ionescu, Vlad
    - Poenaru, Vlad
    - Mihailescu, Vlad Tiberiu
    - Ivanov, Vladimir
    - Li, Wei
    - Wang, Wenchen
    - Jiang, Wenwen
    - Bouaziz, Wes
    - Constable, Will
    - Tang, Xiaocheng
    - Wu, Xiaojian
    - Wang, Xiaolan
    - Wu, Xilun
    - Gao, Xinbo
    - Kleinman, Yaniv
    - Chen, Yanjun
    - Hu, Ye
    - Jia, Ye
    - Qi, Ye
    - Li, Yenda
    - Zhang, Yilin
    - Zhang, Ying
    - Adi, Yossi
    - Nam, Youngjin
    - Yu
    - Wang
    - Zhao, Yu
    - Hao, Yuchen
    - Qian, Yundi
    - Li, Yunlu
    - He, Yuzi
    - Rait, Zach
    - DeVito, Zachary
    - Rosnbrick, Zef
    - Wen, Zhaoduo
    - Yang, Zhenyu
    - Zhao, Zhiwei
    - Ma, Zhiyu
  date: 2024
  serial-number:
    doi: "10.48550/arXiv.2407.21783"

qwen:
  type: report
  title: Qwen Technical Report
  author:
    - Bai, Jinze
    - Bai, Shuai
    - Chu, Yunfei
    - Cui, Zeyu
    - Dang, Kai
    - Deng, Xiaodong
    - Fan, Yang
    - Ge, Wenbin
    - Han, Yu
    - Huang, Fei
    - Hui, Binyuan
    - Ji, Luo
    - Li, Mei
    - Lin, Junyang
    - Lin, Runji
    - Liu, Dayiheng
    - Liu, Gao
    - Lu, Chengqiang
    - Lu, Keming
    - Ma, Jianxin
    - Men, Rui
    - Ren, Xingzhang
    - Ren, Xuancheng
    - Tan, Chuanqi
    - Tan, Sinan
    - Tu, Jianhong
    - Wang, Peng
    - Wang, Shijie
    - Wang, Wei
    - Wu, Shengguang
    - Xu, Benfeng
    - Xu, Jin
    - Yang, An
    - Yang, Hao
    - Yang, Jian
    - Yang, Shusheng
    - Yao, Yang
    - Yu, Bowen
    - Yuan, Hongyi
    - Yuan, Zheng
    - Zhang, Jianwei
    - Zhang, Xingxuan
    - Zhang, Yichang
    - Zhang, Zhenru
    - Zhou, Chang
    - Zhou, Jingren
    - Zhou, Xiaohuan
    - Zhu, Tianhang
  date: 2023
  serial-number:
    doi: "10.48550/arXiv.2309.16609"

squad1:
  type: article
  title: "{SQ}u{AD}: 100,000+ Questions for Machine Comprehension of Text"
  author:
    - Rajpurkar, Pranav
    - Zhang, Jian
    - Lopyrev, Konstantin
    - Liang, Percy
  date: 2016-11
  editor:
    - Su, Jian
    - Duh, Kevin
    - Carreras, Xavier
  page-range: 2383-2392
  url: https://aclanthology.org/D16-1264
  serial-number:
    doi: 10.18653/v1/D16-1264
  parent:
    type: proceedings
    title: Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing
    publisher: Association for Computational Linguistics
    location: Austin, Texas

squad2:
  type: article
  title: "Know What You Don{'}t Know: Unanswerable Questions for {SQ}u{AD}"
  author:
    - Rajpurkar, Pranav
    - Jia, Robin
    - Liang, Percy
  date: 2018-07
  editor:
    - Gurevych, Iryna
    - Miyao, Yusuke
  page-range: 784-789
  url: https://aclanthology.org/P18-2124
  serial-number:
    doi: 10.18653/v1/P18-2124
  abstract: "Extractive reading comprehension systems can often locate the correct answer to a question in a context document, but they also tend to make unreliable guesses on questions for which the correct answer is not stated in the context. Existing datasets either focus exclusively on answerable questions, or use automatically generated unanswerable questions that are easy to identify. To address these weaknesses, we present SQuADRUn, a new dataset that combines the existing Stanford Question Answering Dataset (SQuAD) with over 50,000 unanswerable questions written adversarially by crowdworkers to look similar to answerable ones. To do well on SQuADRUn, systems must not only answer questions when possible, but also determine when no answer is supported by the paragraph and abstain from answering. SQuADRUn is a challenging natural language understanding task for existing models: a strong neural system that gets 86{%} F1 on SQuAD achieves only 66{%} F1 on SQuADRUn. We release SQuADRUn to the community as the successor to SQuAD."
  parent:
    type: proceedings
    title: "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)"
    publisher: Association for Computational Linguistics
    location: Melbourne, Australia

multitask:
  type: article
  title: Multitask Learning
  author: Caruana, Rich
  date: 1997
  page-range: 41-75
  url: https://doi.org/10.1023/A:1007379606734
  serial-number:
    doi: 10.1023/A:1007379606734
    issn: 1573-0565
  abstract: Multitask Learning is an approach to inductive transfer that improves generalization by using the domain information contained in the training signals of related tasks as an inductive bias. It does this by learning tasks in parallel while using a shared representation; what is learned for each task can help other tasks be learned better. This paper reviews prior work on MTL, presents new evidence that MTL in backprop nets discovers task relatedness without the need of supervisory signals, and presents new results for MTL with k-nearest neighbor and kernel regression. In this paper we demonstrate multitask learning in three domains. We explain how multitask learning works, and show that there are many opportunities for multitask learning in real domains. We present an algorithm and results for multitask learning with case-based methods like k-nearest neighbor and kernel regression, and sketch an algorithm for multitask learning in decision trees. Because multitask learning works, can be applied to many different kinds of domains, and can be used with different learning algorithms, we conjecture there will be many opportunities for its use on real-world problems.
  parent:
    type: periodical
    title: Machine Learning
    issue: 1
    volume: 28

hierarchical:
  type: article
  title: A survey of hierarchical classification across different application domains
  author:
    - Silla, Carlos N.
    - Freitas, Alex A.
  date: 2011
  page-range: 31-72
  url: https://doi.org/10.1007/s10618-010-0175-9
  serial-number:
    doi: 10.1007/s10618-010-0175-9
    issn: 1573-756X
  abstract: In this survey we discuss the task of hierarchical classification. The literature about this field is scattered across very different application domains and for that reason research in one domain is often done unaware of methods developed in other domains. We define what is the task of hierarchical classification and discuss why some related tasks should not be considered hierarchical classification. We also present a new perspective about some existing hierarchical classification approaches, and based on that perspective we propose a new unifying framework to classify the existing approaches. We also present a review of empirical comparisons of the existing methods reported in the literature as well as a conceptual comparison of those methods at a high level of abstraction, discussing their advantages and disadvantages.
  parent:
    type: periodical
    title: Data Mining and Knowledge Discovery
    issue: 1
    volume: 22

doccano:
  type: misc
  title: "{doccano}: Text Annotation Tool for Human"
  author:
    - Nakayama, Hiroki
    - Kubo, Takahiro
    - Kamura, Junya
    - Taniguchi, Yasufumi
    - Liang, Xu
  date: 2018
  url: https://github.com/doccano/doccano

jmespath:
  type: web
  title: "JMESPath is a query language for JSON"
  author:
    - James Saryerwinnie
  url: https://jmespath.org/

jsonpath:
  type: blog
  title: "JSONPath - XPath for JSON"
  author:
    - Stefan Goessner
  date: 2007
  url: https://goessner.net/articles/JsonPath/

sparql:
  type: report
  title: "SPARQL Query Language for RDF"
  organization: W3C
  url: https://www.w3.org/TR/sparql11-query/

graphviz:
  type: reference
  title: "Graphviz - Graph Visualization Software"
  organization: Graphviz
  url: https://graphviz.org/

handlebars:
  type: reference
  title: "Handlebars - Minimal Templating on Steroids"
  organization: Handlebars
  url: https://handlebarsjs.com/

fastapi:
  type: reference
  title: "FastAPI - Fast (high-performance) API framework for Python"
  organization: FastAPI
  url: https://fastapi.tiangolo.com/
