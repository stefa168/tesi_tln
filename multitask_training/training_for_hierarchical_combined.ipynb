{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Labels preparation",
   "id": "d63575cab41cd6a4"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:26.730463Z",
     "start_time": "2024-11-17T22:05:26.721700Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "from multitask_training.BertForHierarchicalClassification import BertForHierarchicalClassification\n",
    "\n",
    "df = pd.read_csv('./data_cleaned_manual_combined.csv')\n",
    "\n",
    "labels_gs = df['Global Subject'].unique()\n",
    "labels_qi = df['Question Intent'].unique()\n",
    "\n",
    "id2label_gs = {i: label for i, label in enumerate(labels_gs)}\n",
    "label2id_gs = {label: i for i, label in enumerate(labels_gs)}\n",
    "\n",
    "id2label_qi = {i: label for i, label in enumerate(labels_qi)}\n",
    "label2id_qi = {label: i for i, label in enumerate(labels_qi)}"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Now we'll preprocess all the data by encoding it",
   "id": "8f498aa5ca72c31b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:27.005787Z",
     "start_time": "2024-11-17T22:05:26.765075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "\n",
    "# https://huggingface.co/docs/transformers/v4.46.2/en/model_doc/auto#transformers.AutoTokenizer.from_pretrained\n",
    "# https://huggingface.co/docs/transformers/v4.46.2/en/model_doc/bert#transformers.BertTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def preprocess_data(example):\n",
    "    question = example['Question']\n",
    "\n",
    "    # https://huggingface.co/docs/transformers/v4.46.2/en/main_classes/tokenizer#transformers.PreTrainedTokenizer.__call__\n",
    "    encodings = tokenizer(question, padding=\"max_length\", truncation=True, max_length=128)\n",
    "    label_gs = label2id_gs[example['Global Subject']]\n",
    "    label_qi = label2id_qi[example['Question Intent']]\n",
    "\n",
    "    encodings.update({'labels_main': label_gs, 'labels_sub': label_qi})\n",
    "\n",
    "    return encodings"
   ],
   "id": "2f5afe7fcd649c24",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:27.154253Z",
     "start_time": "2024-11-17T22:05:27.020717Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_data, remove_columns=dataset.column_names)\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "\n",
    "tokenized_dataset"
   ],
   "id": "38e8bbb71d8961d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/855 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2baaea7a17e47ec9a690d6ba918bae5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels_main', 'labels_sub'],\n",
       "    num_rows: 855\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:27.195431Z",
     "start_time": "2024-11-17T22:05:27.188307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_testvalid = tokenized_dataset.train_test_split(test_size=0.8, seed=42)\n",
    "test_valid = train_testvalid['test'].train_test_split(test_size=0.5, seed=42)\n",
    "\n",
    "train_dataset = train_testvalid['train']\n",
    "eval_dataset = test_valid['train']\n",
    "test_dataset = test_valid['test']"
   ],
   "id": "166856fab5c4795",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:27.233276Z",
     "start_time": "2024-11-17T22:05:27.229836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # Unpack predictions and labels\n",
    "    predictions, labels = eval_pred\n",
    "\n",
    "    # If predictions and labels are tuples, unpack them\n",
    "    if isinstance(predictions, tuple):\n",
    "        logits_main, logits_sub = predictions\n",
    "    else:\n",
    "        # If not a tuple, handle accordingly (unlikely in this case)\n",
    "        logits_main, logits_sub = predictions\n",
    "\n",
    "    if isinstance(labels, tuple):\n",
    "        labels_main, labels_sub = labels\n",
    "    else:\n",
    "        # If labels are not a tuple, they might be a dict or array\n",
    "        labels_main = labels['labels_main']\n",
    "        labels_sub = labels['labels_sub']\n",
    "\n",
    "    # Convert logits to predicted class indices\n",
    "    preds_main = np.argmax(logits_main, axis=1)\n",
    "    preds_sub = np.argmax(logits_sub, axis=1)\n",
    "\n",
    "    # Compute metrics for main topic\n",
    "    acc_main = accuracy_score(labels_main, preds_main)\n",
    "    precision_main, recall_main, f1_main, _ = precision_recall_fscore_support(\n",
    "        labels_main, preds_main, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    # Compute metrics for subtopic\n",
    "    acc_sub = accuracy_score(labels_sub, preds_sub)\n",
    "    precision_sub, recall_sub, f1_sub, _ = precision_recall_fscore_support(\n",
    "        labels_sub, preds_sub, average='weighted', zero_division=0\n",
    "    )\n",
    "\n",
    "    # Combine metrics into a dictionary\n",
    "    metrics = {\n",
    "        'accuracy_main': acc_main,\n",
    "        'precision_main': precision_main,\n",
    "        'recall_main': recall_main,\n",
    "        'f1_main': f1_main,\n",
    "        'accuracy_sub': acc_sub,\n",
    "        'precision_sub': precision_sub,\n",
    "        'recall_sub': recall_sub,\n",
    "        'f1_sub': f1_sub,\n",
    "    }\n",
    "\n",
    "    return metrics\n"
   ],
   "id": "3f038a121898ad24",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:27.275617Z",
     "start_time": "2024-11-17T22:05:27.267578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "print(f\"Current CUDA device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device name: {torch.cuda.get_device_name(torch.cuda.current_device())}\")\n"
   ],
   "id": "6b6ae01b592ca73",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current CUDA device: 0\n",
      "Device name: NVIDIA GeForce RTX 3070 Ti\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:05:30.524371Z",
     "start_time": "2024-11-17T22:05:27.293995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='tesi')"
   ],
   "id": "71218ef163a452ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:6i39e5gh) before initializing another..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_main</td><td>▁▄▅▆▆▇▇▇██▇▇██▇██████</td></tr><tr><td>eval/accuracy_sub</td><td>▁▁▃▄▅▅▆▆▆▇▆▇▇▇▇██████</td></tr><tr><td>eval/f1_main</td><td>▁▅▆▆▇▇▇▇███▇██▇██████</td></tr><tr><td>eval/f1_sub</td><td>▁▁▃▄▅▅▆▆▆▇▆▇▇▇███████</td></tr><tr><td>eval/loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision_main</td><td>▁▅▆▇▇▇▇▇███▇██▇██████</td></tr><tr><td>eval/precision_sub</td><td>▁▂▃▄▅▅▆▆▆▇▆▆▇████████</td></tr><tr><td>eval/recall_main</td><td>▁▄▅▆▆▇▇▇██▇▇██▇██████</td></tr><tr><td>eval/recall_sub</td><td>▁▁▃▄▅▅▆▆▆▇▆▇▇▇▇██████</td></tr><tr><td>eval/runtime</td><td>▄▂▃▃▃▅▃▂▁▁▇▆▃▂▂▄▃▃▂▅█</td></tr><tr><td>eval/samples_per_second</td><td>▅▇▅▆▆▃▅▇██▁▃▆▇▇▅▆▅▇▄▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▇▅▆▆▃▅▇██▁▃▆▇▇▅▆▅▇▄▁</td></tr><tr><td>test/accuracy_main</td><td>▁</td></tr><tr><td>test/accuracy_sub</td><td>▁</td></tr><tr><td>test/f1_main</td><td>▁</td></tr><tr><td>test/f1_sub</td><td>▁</td></tr><tr><td>test/loss</td><td>▁</td></tr><tr><td>test/precision_main</td><td>▁</td></tr><tr><td>test/precision_sub</td><td>▁</td></tr><tr><td>test/recall_main</td><td>▁</td></tr><tr><td>test/recall_sub</td><td>▁</td></tr><tr><td>test/runtime</td><td>▁</td></tr><tr><td>test/samples_per_second</td><td>▁</td></tr><tr><td>test/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇█████</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▇▇▇▇▇▇██████</td></tr><tr><td>train/grad_norm</td><td>▁▃▄▄▃▆▃▃▄▂▆▅▂█▅▁▃▃▆▄</td></tr><tr><td>train/learning_rate</td><td>▅██▇▇▆▆▆▅▅▅▄▄▃▃▃▂▂▁▁</td></tr><tr><td>train/loss</td><td>█▇▆▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy_main</td><td>0.85882</td></tr><tr><td>eval/accuracy_sub</td><td>0.67059</td></tr><tr><td>eval/f1_main</td><td>0.85909</td></tr><tr><td>eval/f1_sub</td><td>0.62389</td></tr><tr><td>eval/loss</td><td>1.90889</td></tr><tr><td>eval/precision_main</td><td>0.8623</td></tr><tr><td>eval/precision_sub</td><td>0.63333</td></tr><tr><td>eval/recall_main</td><td>0.85882</td></tr><tr><td>eval/recall_sub</td><td>0.67059</td></tr><tr><td>eval/runtime</td><td>0.2623</td></tr><tr><td>eval/samples_per_second</td><td>324.107</td></tr><tr><td>eval/steps_per_second</td><td>22.878</td></tr><tr><td>test/accuracy_main</td><td>0.9186</td></tr><tr><td>test/accuracy_sub</td><td>0.65116</td></tr><tr><td>test/f1_main</td><td>0.91744</td></tr><tr><td>test/f1_sub</td><td>0.60189</td></tr><tr><td>test/loss</td><td>1.62964</td></tr><tr><td>test/precision_main</td><td>0.9229</td></tr><tr><td>test/precision_sub</td><td>0.59625</td></tr><tr><td>test/recall_main</td><td>0.9186</td></tr><tr><td>test/recall_sub</td><td>0.65116</td></tr><tr><td>test/runtime</td><td>0.2352</td></tr><tr><td>test/samples_per_second</td><td>365.689</td></tr><tr><td>test/steps_per_second</td><td>25.513</td></tr><tr><td>total_flos</td><td>900203377766400.0</td></tr><tr><td>train/epoch</td><td>20</td></tr><tr><td>train/global_step</td><td>860</td></tr><tr><td>train/grad_norm</td><td>24.54011</td></tr><tr><td>train/learning_rate</td><td>0</td></tr><tr><td>train/loss</td><td>1.0633</td></tr><tr><td>train_loss</td><td>2.21829</td></tr><tr><td>train_runtime</td><td>227.5552</td></tr><tr><td>train_samples_per_second</td><td>60.117</td></tr><tr><td>train_steps_per_second</td><td>3.779</td></tr></table><br/></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">worthy-oath-9</strong> at: <a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/6i39e5gh' target=\"_blank\">https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/6i39e5gh</a><br/> View project at: <a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi' target=\"_blank\">https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find logs at: <code>./wandb/run-20241117_181622-6i39e5gh/logs</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Successfully finished last run (ID:6i39e5gh). Initializing new run:<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.18.7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/stefa/IdeaProjects/tesi_tln/multitask_training/wandb/run-20241117_230527-m66m8oq2</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/m66m8oq2' target=\"_blank\">royal-pyramid-10</a></strong> to <a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi' target=\"_blank\">https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/m66m8oq2' target=\"_blank\">https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/m66m8oq2</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/stefano-porta800-universit-degli-studi-di-torino/tesi/runs/m66m8oq2?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7647903c9b50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:06:49.969356Z",
     "start_time": "2024-11-17T22:05:30.530605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model = BertForHierarchicalClassification.from_pretrained(\n",
    "    # 'bert-base-uncased',\n",
    "    'distilbert-base-uncased',\n",
    "    num_main_topics=len(labels_gs),\n",
    "    num_subtopics=len(labels_qi)\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,  # Warmup for the first 10% of steps\n",
    "    lr_scheduler_type='linear',  # Linear scheduler\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    save_strategy='epoch',\n",
    "    logging_strategy='epoch',\n",
    "    eval_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    load_best_model_at_end=True,  # Load the best model at the end based on evaluation metric\n",
    "    metric_for_best_model='f1_sub',  # Use subtopic F1-score to determine the best model\n",
    "    greater_is_better=True,  # Higher metric indicates a better model,\n",
    "    report_to='wandb'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(f\"Trainer is using device: {trainer.args.device}\")\n",
    "\n",
    "trainer.train()"
   ],
   "id": "18a42601978d5ec4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of BertForHierarchicalClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier_main.bias', 'classifier_main.weight', 'classifier_sub.bias', 'classifier_sub.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer is using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 01:18, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Main</th>\n",
       "      <th>Precision Main</th>\n",
       "      <th>Recall Main</th>\n",
       "      <th>F1 Main</th>\n",
       "      <th>Accuracy Sub</th>\n",
       "      <th>Precision Sub</th>\n",
       "      <th>Recall Sub</th>\n",
       "      <th>F1 Sub</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5.560800</td>\n",
       "      <td>5.324038</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.069252</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.109649</td>\n",
       "      <td>0.154971</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.154971</td>\n",
       "      <td>0.041587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.288600</td>\n",
       "      <td>5.149520</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.348022</td>\n",
       "      <td>0.374269</td>\n",
       "      <td>0.296110</td>\n",
       "      <td>0.154971</td>\n",
       "      <td>0.024016</td>\n",
       "      <td>0.154971</td>\n",
       "      <td>0.041587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5.106100</td>\n",
       "      <td>5.090141</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.162433</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.218671</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.043004</td>\n",
       "      <td>0.192982</td>\n",
       "      <td>0.070041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.810900</td>\n",
       "      <td>4.728669</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.450157</td>\n",
       "      <td>0.438596</td>\n",
       "      <td>0.371537</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.095824</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.114372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4.394600</td>\n",
       "      <td>4.426216</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.424773</td>\n",
       "      <td>0.482456</td>\n",
       "      <td>0.429709</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.180224</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.177347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>4.082100</td>\n",
       "      <td>4.175373</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.598022</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.526788</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.115591</td>\n",
       "      <td>0.280702</td>\n",
       "      <td>0.158887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3.718800</td>\n",
       "      <td>3.890641</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.655725</td>\n",
       "      <td>0.643275</td>\n",
       "      <td>0.635411</td>\n",
       "      <td>0.318713</td>\n",
       "      <td>0.166497</td>\n",
       "      <td>0.318713</td>\n",
       "      <td>0.201344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>3.429100</td>\n",
       "      <td>3.684939</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.729106</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.716613</td>\n",
       "      <td>0.347953</td>\n",
       "      <td>0.198069</td>\n",
       "      <td>0.347953</td>\n",
       "      <td>0.235117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3.215200</td>\n",
       "      <td>3.571958</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.741998</td>\n",
       "      <td>0.713450</td>\n",
       "      <td>0.709942</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.239887</td>\n",
       "      <td>0.365497</td>\n",
       "      <td>0.252559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.981300</td>\n",
       "      <td>3.442618</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.753891</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.743847</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.253652</td>\n",
       "      <td>0.380117</td>\n",
       "      <td>0.270817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.817000</td>\n",
       "      <td>3.377511</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.751654</td>\n",
       "      <td>0.748538</td>\n",
       "      <td>0.743444</td>\n",
       "      <td>0.406433</td>\n",
       "      <td>0.272539</td>\n",
       "      <td>0.406433</td>\n",
       "      <td>0.302723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.634600</td>\n",
       "      <td>3.341086</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.737828</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>0.724332</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.339627</td>\n",
       "      <td>0.397661</td>\n",
       "      <td>0.312716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.519200</td>\n",
       "      <td>3.266464</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.759851</td>\n",
       "      <td>0.742690</td>\n",
       "      <td>0.744867</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.340917</td>\n",
       "      <td>0.429825</td>\n",
       "      <td>0.341386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.417500</td>\n",
       "      <td>3.189856</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.761930</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.757101</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.351857</td>\n",
       "      <td>0.435673</td>\n",
       "      <td>0.339040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.341400</td>\n",
       "      <td>3.231014</td>\n",
       "      <td>0.733918</td>\n",
       "      <td>0.761346</td>\n",
       "      <td>0.733918</td>\n",
       "      <td>0.735100</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.338933</td>\n",
       "      <td>0.432749</td>\n",
       "      <td>0.338944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.231000</td>\n",
       "      <td>3.151471</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.777539</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.768451</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375982</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.348355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.229300</td>\n",
       "      <td>3.134581</td>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.782431</td>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.770761</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.339047</td>\n",
       "      <td>0.450292</td>\n",
       "      <td>0.353215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.175800</td>\n",
       "      <td>3.094497</td>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.759456</td>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.751144</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.364915</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.358299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.111800</td>\n",
       "      <td>3.075418</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.771718</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.765703</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.348339</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.355831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.111900</td>\n",
       "      <td>3.078139</td>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.751462</td>\n",
       "      <td>0.751624</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.349670</td>\n",
       "      <td>0.459064</td>\n",
       "      <td>0.359768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=220, training_loss=3.3088507305492056, metrics={'train_runtime': 78.2865, 'train_samples_per_second': 43.686, 'train_steps_per_second': 2.81, 'total_flos': 225050844441600.0, 'train_loss': 3.3088507305492056, 'epoch': 20.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:06:50.946350Z",
     "start_time": "2024-11-17T22:06:50.071141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ],
   "id": "aa7c18a92e376cb3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.078139305114746, 'eval_accuracy_main': 0.7514619883040936, 'eval_precision_main': 0.7590364719806276, 'eval_recall_main': 0.7514619883040936, 'eval_f1_main': 0.7516241836796272, 'eval_accuracy_sub': 0.4590643274853801, 'eval_precision_sub': 0.3496699982690117, 'eval_recall_sub': 0.4590643274853801, 'eval_f1_sub': 0.3597683150431605, 'eval_runtime': 0.8713, 'eval_samples_per_second': 392.511, 'eval_steps_per_second': 25.249, 'epoch': 20.0}\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:06:51.585413Z",
     "start_time": "2024-11-17T22:06:51.013395Z"
    }
   },
   "cell_type": "code",
   "source": "trainer.save_model(f'./models/{wandb.run.name}')",
   "id": "540ae95a005d55f6",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-17T22:06:52.491019Z",
     "start_time": "2024-11-17T22:06:51.598489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Access the predictions and true labels\n",
    "# logits_main = predictions.predictions['logits_main']\n",
    "# logits_sub = predictions.predictions['logits_sub']\n",
    "# labels_main = predictions.label_ids['labels_main']\n",
    "# labels_sub = predictions.label_ids['labels_sub']\n",
    "# \n",
    "# # Convert logits to predicted class labels\n",
    "# preds_main = np.argmax(logits_main, axis=1)\n",
    "# preds_sub = np.argmax(logits_sub, axis=1)\n",
    "predictions.metrics"
   ],
   "id": "cdb2033fcfc1566",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 3.283393383026123,\n",
       " 'test_accuracy_main': 0.7280701754385965,\n",
       " 'test_precision_main': 0.740716548903624,\n",
       " 'test_recall_main': 0.7280701754385965,\n",
       " 'test_f1_main': 0.7304996561138977,\n",
       " 'test_accuracy_sub': 0.39473684210526316,\n",
       " 'test_precision_sub': 0.25404933512683364,\n",
       " 'test_recall_sub': 0.39473684210526316,\n",
       " 'test_f1_sub': 0.27758337527090454,\n",
       " 'test_runtime': 0.8877,\n",
       " 'test_samples_per_second': 385.266,\n",
       " 'test_steps_per_second': 24.783}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
